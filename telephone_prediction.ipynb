{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"telephone_prediction.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 Truffle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QrHNfuRlBtBD"},"source":["# Summary\n","MLEnd dataset is a dataset of spoken numerals collected in 2021. It consists of 20,000 audio files. 32 different numerals have been included: 0-20, 30, 40, 50, 60, 70, 80, 90, 100, 1000, 1 million, 1 billion. This solution is going to first train a model developed in the other section and then attempt to use that model to predict the telephone number from audio files of recorded spoken telephone numbers.\n"]},{"cell_type":"markdown","metadata":{"id":"43uZ_LzW2sRL"},"source":["# Prepare and train the model"]},{"cell_type":"code","metadata":{"id":"zysBQ-C8jDZ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618310793371,"user_tz":-60,"elapsed":24955,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"59715f20-6f77-4391-d74a-d18d5f19e7f3"},"source":["#library import\n","from google.colab import drive\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import os, sys, re, pickle, glob\n","import urllib.request\n","import zipfile\n","\n","from random import randrange\n","\n","#from IPython.display import Audio\n","import IPython.display as ipd\n","from tqdm import tqdm\n","import librosa\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lA4m4fziB6kc"},"source":["## Dataset preparation"]},{"cell_type":"markdown","metadata":{"id":"N_u0AN6YCFLL"},"source":["Check that the dataset has been donwloaded and is available for use - there should be 20,000 files."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2tXV3A2CGLi","executionInfo":{"status":"ok","timestamp":1618310889939,"user_tz":-60,"elapsed":93415,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"4ad2dfad-e9e8-4834-8c5d-ea817e262dac"},"source":["files = glob.glob('/content/drive/MyDrive/Data/MLEnd/training/*/*.wav')\n","len(files)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20000"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"AXpXwlfwCL6_"},"source":["Check the dataset information from the 'trainingMLEnd.csv' file and save them to a variable."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"7Z8NO4z5COjY","executionInfo":{"status":"ok","timestamp":1618308467440,"user_tz":-60,"elapsed":978,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"c6caf989-1f86-45ab-a097-c11995837f1b"},"source":["labels = pd.read_csv('/content/drive/MyDrive/Data/MLEnd/trainingMLEnd.csv')\n","labels.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File ID</th>\n","      <th>digit_label</th>\n","      <th>participant</th>\n","      <th>intonation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000000.wav</td>\n","      <td>4</td>\n","      <td>S73</td>\n","      <td>question</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0000001.wav</td>\n","      <td>2</td>\n","      <td>S88</td>\n","      <td>excited</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0000002.wav</td>\n","      <td>70</td>\n","      <td>S5</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0000003.wav</td>\n","      <td>2</td>\n","      <td>S85</td>\n","      <td>bored</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0000004.wav</td>\n","      <td>4</td>\n","      <td>S30</td>\n","      <td>excited</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       File ID  digit_label participant intonation\n","0  0000000.wav            4         S73   question\n","1  0000001.wav            2         S88    excited\n","2  0000002.wav           70          S5    neutral\n","3  0000003.wav            2         S85      bored\n","4  0000004.wav            4         S30    excited"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"N0VRnS_m15NL"},"source":["The following function will be used for feature extraction."]},{"cell_type":"code","metadata":{"id":"W34grCuUDg2K","executionInfo":{"status":"ok","timestamp":1618310890582,"user_tz":-60,"elapsed":638,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["def getPitch(x,fs,winLen=0.02):\n","  #winLen = 0.02 \n","  p = winLen*fs\n","  frame_length = int(2**int(p-1).bit_length())\n","  hop_length = frame_length//2\n","  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n","                                                 frame_length=frame_length,hop_length=hop_length)\n","  return f0,voiced_flag"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u3QbWAQYDnZU"},"source":["The following function takes a number of files and creates a NumPy array containing the specified audio features used as predictors (`X`) and their labels (`z`)."]},{"cell_type":"code","metadata":{"id":"d8gK0JFGDmnp","executionInfo":{"status":"ok","timestamp":1618310891290,"user_tz":-60,"elapsed":1341,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["def getXy(files,labels_file,scale_audio=False, onlySingleDigit=False):\n","  X,y,z =[],[],[]\n","  for file in tqdm(files):\n","    fileID = file.split('/')[-1]\n","    # yi is our label - in this case intonation\n","    yi = list(labels_file[labels_file['File ID']==fileID]['intonation'])[0]\n","    zi = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n","\n","    if onlySingleDigit and zi>9:\n","      continue\n","    else:\n","      fs = None # if None, fs would be 22050\n","      x, fs = librosa.load(file,sr=fs)\n","      if scale_audio: x = x/np.max(np.abs(x))\n","      f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n","          \n","      power = np.sum(x**2)/len(x)\n","      pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n","      pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n","      voiced_fr = np.mean(voiced_flag)\n","      crossing_rate = np.sum(librosa.feature.zero_crossing_rate(x))\n","      spectral_centroid = np.mean(librosa.feature.spectral_centroid(x, fs))\n","      spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(x, fs))\n","      spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(x, fs))\n","      chroma_stft = np.mean(librosa.feature.chroma_stft(x, fs))\n","      rmse = np.mean(librosa.feature.rms(x))\n","      \n","\n","      xi = [power,pitch_mean,pitch_std,voiced_fr, crossing_rate, spectral_centroid, \n","            spectral_rolloff, spectral_bandwidth, chroma_stft,rmse]\n","      X.append(xi)\n","      y.append(yi)\n","      z.append(zi)\n","  return np.array(X),np.array(y), np.array(z)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lE7Igdv7FU1n"},"source":["## The model\n","The model will use the following features extracted from the audio files (index, name):\n","- 3, fraction of voiced region\n","- 4, zero crossing rate\n","- 5, spectral centroid\n","- 6, spectral rolloff\n","- 9, rmse\n","\n","<br><br>\n","The model used will be **Logistic Regression**<br>\n","Using this model on a smaller dataset produced correct training prediction 32% of the time and validation prediction 31% of the time. In the next section, I will run this model on the whole dataset available."]},{"cell_type":"markdown","metadata":{"id":"J6NhlHihYE3K"},"source":["## Training and validation\n","For training of the model I will use all audio files with numerals 0-9. I am going to create a dataset of all files with all ten features and save it as csv for future use. This task will take a long time and therefore I only want to do it once. One audio file was causing errors, therefore I will end up with 2 csv files of length 19999 each:\n","- `feeatures.csv` - all 10 features I identified earlier - I extracted all 10 in case they could be useful for any further exploration\n","- `numerals.csv` - corresponding numerals<br><br>\n","\n","These files can also be downloaded from my GitHub:<br>\n","https://github.com/maciejtarsa/MLEnd-Spoken-Numerals"]},{"cell_type":"code","metadata":{"id":"kCUxFyZsYSas","executionInfo":{"status":"ok","timestamp":1618310908433,"user_tz":-60,"elapsed":473,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# the next line is commented out because I only needed to run it once\n","#X,y,z = getXy(files[:],labels_file=labels,scale_audio=True, onlySingleDigit=False)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywPPXJkBYTui"},"source":["Instead of the above line, I will import the csv files I have created. I will import the features into a vector `X` and the numerals into a vector `z`."]},{"cell_type":"code","metadata":{"id":"pyXtUmmNYvBg","executionInfo":{"status":"ok","timestamp":1618310912542,"user_tz":-60,"elapsed":1560,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["import csv\n","# import the features from a csv file into an array\n","data_x = []\n","with open('/content/drive/MyDrive/Data/MLEnd/features.csv', 'r') as rf:\n","    reader = csv.reader(rf, delimiter=',')\n","    for row in reader:\n","      data_x.append(row[1:11])\n","\n","X = np.array(data_x).astype(np.float)\n","X = np.delete(X, 0, axis=0)\n","\n","# import the numerals from a csv file into an array\n","data_z=[]\n","with open('/content/drive/MyDrive/Data/MLEnd/numerals.csv', 'r') as rf:\n","    reader = csv.reader(rf, delimiter=',')\n","    for row in reader:\n","      data_z.append(int(row[1]))\n","\n","z = np.array(data_z)\n","z = np.delete(z, [0])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ra4R0ZKeYz2M"},"source":["I only want to keep the data for numerals 0-9."]},{"cell_type":"code","metadata":{"id":"CPELe8BXY3O-","executionInfo":{"status":"ok","timestamp":1618310916061,"user_tz":-60,"elapsed":849,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# Extract a list of indeces from z where numeral is less than 10\n","num_index = np.where(z < 10)\n","# amend X to only keep features for numerals 0-9\n","X = np.take(X, num_index, axis=0)\n","X = np.squeeze(X)\n","# amend z to only keep numerals 0-9\n","z = np.take(z, num_index)\n","z = np.squeeze(z)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_XtK7ulwdnHd"},"source":["With this, I end up with 6533 audio files for numerals 0-9. Next, I will run them on the model chosen earlier."]},{"cell_type":"markdown","metadata":{"id":"2tZKccAWdxr3"},"source":["### Run the model"]},{"cell_type":"code","metadata":{"id":"SeRgcHeR2gKC","executionInfo":{"status":"ok","timestamp":1618311001612,"user_tz":-60,"elapsed":735,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# import the model\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hth7b77qbc1K","executionInfo":{"status":"ok","timestamp":1618311004228,"user_tz":-60,"elapsed":756,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"f94c7d3b-d8c8-43fd-8dc4-428de8cdc89e"},"source":["# select the feautures extracted\n","XX = X[:,[3, 4, 5, 6, 9]]\n","X_train, X_val, z_train, z_val = train_test_split(XX,z,test_size=0.4)\n","# normalise the predictors\n","X_train = (X_train-X_train.mean(0))/X_train.std(0)\n","X_val = (X_val-X_val.mean(0))/X_val.std(0)\n","\n","# run the model\n","model_numerals = LogisticRegression()\n","model_numerals.fit(X_train,z_train)\n","zt_p = model_numerals.predict(X_train)\n","zv_p = model_numerals.predict(X_val)\n","\n","print(\"The final model produced the following testing and validation values:\")\n","print(f\"Testing: {np.mean(zt_p==z_train)}\")\n","print(f\"Validation: {np.mean(zv_p==z_val)}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The final model produced the following testing and validation values:\n","Testing: 0.303648890022965\n","Validation: 0.30642693190512627\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X-itW52RfRK9"},"source":["My final model achieved the testing accuracy of 30% and validation accuracy of 31% using a dataset of 6533 audio files."]},{"cell_type":"markdown","metadata":{"id":"Gzh5rTCRYuYw"},"source":["# Telephone number use case\n","In this section, I will create a product that will attempt to identify all digits of a telephone number from an audio file recording of person reciting a telephone number. The model trained in previous section is going to be used.<br><br>\n","For the purpose of this exercise, UK mobile numbers are going to be used (11 numerals). It is assumed that the speaker is pronouncing each number as a digit, and that zero is pronouncaed as 'zero' rather than for example 'o'."]},{"cell_type":"markdown","metadata":{"id":"nWZ-0-GXHAJ_"},"source":["### Exploration of the problem"]},{"cell_type":"markdown","metadata":{"id":"YLQ0KYN3RQz7"},"source":["#### Load an audio file:\n","Upload data to collaborate panel on the left<br><br>\n","Recordings used for this use cases can be found on my github at:<br>\n","https://github.com/maciejtarsa/MLEnd-Spoken-Numerals/tree/main/telephone_numbers"]},{"cell_type":"code","metadata":{"id":"q9M6Z6nLTxgG","executionInfo":{"status":"ok","timestamp":1618311114728,"user_tz":-60,"elapsed":461,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# set a variable for the audio file\n","tel_file = './V_2.wav'"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315,"output_embedded_package_id":"1B755YtsgDbEfdWZNcRo0DlIGWt25Nzyi"},"id":"BmsE8LeAUCeC","executionInfo":{"status":"ok","timestamp":1618311120336,"user_tz":-60,"elapsed":3524,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"6590fdb8-4ae0-4fd6-cf3a-0bd1285a9b65"},"source":["# display s sound wave and play\n","fs = None # Sampling frequency. If None, fs would be 22050\n","x, fs = librosa.load(tel_file,sr=fs)\n","t = np.arange(len(x))/fs\n","plt.plot(t,x)\n","plt.xlabel('time (sec)')\n","plt.ylabel('amplitude')\n","plt.show()\n","display(ipd.Audio(tel_file))"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"BUHhwGXMUpdR"},"source":["I now have the file in the working environment, I then want to split it on silence."]},{"cell_type":"markdown","metadata":{"id":"7zNoyWy_RoNZ"},"source":["#### Split the audio file"]},{"cell_type":"markdown","metadata":{"id":"IGUfm68keB-3"},"source":["In order to split the sound file on silence I can use functionality from pydub library. I tried using librosa for this, however it was not splitting the files into 11 chunks effectively, hence I decided to attempt using another library"]},{"cell_type":"code","metadata":{"id":"3xmi2opAcYL5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618311129389,"user_tz":-60,"elapsed":4407,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"926f5881-3ebf-464b-d78f-ceaa457d638c"},"source":["# need to install pydub\n","!pip install pydub"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting pydub\n","  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3RjAKtUhbTiC","executionInfo":{"status":"ok","timestamp":1618311133307,"user_tz":-60,"elapsed":490,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["from pydub import AudioSegment\n","from pydub.silence import split_on_silence\n","\n","# a function for splitting a file into chunks\n","def split(filepath):\n","  sound = AudioSegment.from_wav(filepath)\n","  dBFS = sound.dBFS\n","  chunks = split_on_silence(sound, \n","    min_silence_len = 250,\n","    silence_thresh = dBFS-16)\n","  return chunks"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWmeiqG52AfF","executionInfo":{"status":"ok","timestamp":1618311137439,"user_tz":-60,"elapsed":1003,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# chunk the file\n","chunks = split(tel_file)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YSbTKaoyKX9","executionInfo":{"status":"ok","timestamp":1618311333466,"user_tz":-60,"elapsed":443,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# save chunks as .wav files in the local collab environment\n","for i, chunk in enumerate(chunks):\n","  chunk.export(\"./chunk{0}.wav\".format(i), format=\"wav\")"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJqV0UmazjAs","executionInfo":{"status":"ok","timestamp":1618311337218,"user_tz":-60,"elapsed":413,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"15063f85-3d45-48b5-fba6-0bdbade9d02d"},"source":["# create a list of .wav files to import\n","numeral_files = glob.glob(\"./chunk*.wav\".format(tel_file))\n","len(numeral_files)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"_U-BxuHhjD5O"},"source":["#### Get features for each numeral\n","At this stage I have 11 files with numerals for each telephone number. I now need to extract the features for each numeral."]},{"cell_type":"code","metadata":{"id":"EJ9beo0mjOFp","executionInfo":{"status":"ok","timestamp":1618311340779,"user_tz":-60,"elapsed":640,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# a function for extracting the features\n","def getX(numerals):\n","  X = []\n","  for file in tqdm(numerals):\n","\n","    fs = None # if None, fs would be 22050\n","    x, fs = librosa.load(file,sr=fs)\n","    x = x/np.max(np.abs(x))\n","    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n","          \n","    power = np.sum(x**2)/len(x)\n","    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n","    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n","    voiced_fr = np.mean(voiced_flag)\n","    crossing_rate = np.sum(librosa.feature.zero_crossing_rate(x))\n","    spectral_centroid = np.mean(librosa.feature.spectral_centroid(x, fs))\n","    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(x, fs))\n","    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(x, fs))\n","    chroma_stft = np.mean(librosa.feature.chroma_stft(x, fs))\n","    rmse = np.mean(librosa.feature.rms(x))\n","      \n","\n","    xi = [power,pitch_mean,pitch_std,voiced_fr, crossing_rate, spectral_centroid, \n","            spectral_rolloff, spectral_bandwidth, chroma_stft,rmse]\n","    X.append(xi)\n","\n","  return np.array(X)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kCReOvONvUUF"},"source":["Run the above function for the numerals"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqAnmdkvvTFK","executionInfo":{"status":"ok","timestamp":1618311347275,"user_tz":-60,"elapsed":3648,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"4b8064f6-eaa3-4f4a-eb60-ec8baa520b91"},"source":["X = getX(numeral_files)\n","print('\\n\\nThe shape of X is', X.shape) "],"execution_count":31,"outputs":[{"output_type":"stream","text":["100%|██████████| 11/11 [00:02<00:00,  4.22it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","The shape of X is (11, 10)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"MFU0FYLavuq4"},"source":["I now have an array of 11 numerals with 10 features for each."]},{"cell_type":"markdown","metadata":{"id":"a-yIhYefRsQP"},"source":["#### Run the model\n","Run the model to predict the number given."]},{"cell_type":"code","metadata":{"id":"8axqREljwUwo","executionInfo":{"status":"ok","timestamp":1618311349314,"user_tz":-60,"elapsed":661,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["def runModel():\n","  # select the relevant features\n","  XX = X[:,[3, 4, 5, 7, 9]]\n","  # normalise the predictor\n","  XX = (XX-XX.mean(0))/XX.std(0)\n","  # run the prediction\n","  number_prediction = model_numerals.predict(XX)\n","  #print('The predicted number is:')\n","  # print the number as string\n","  string = ''\n","  for no in number_prediction:\n","    #print(no, end='')\n","    string+=str(no)\n","\n","  # and add it to the dataframe\n","  telephone_results.loc[telephone_results['File'] == tel_file[2:], 'Predicted'] = string\n","  # get the value of the actual number\n","  actual_string = telephone_results.loc[telephone_results['File'] == tel_file[2:], 'Actual'].iloc[0]\n","  # calculate the accuracy by comparing the strings\n","  sum = 0\n","  for i in range(11):\n","    if string[i] == actual_string[i]:\n","      sum += 1\n","  telephone_results.loc[telephone_results['File'] == tel_file[2:], 'Accuracy'] = sum/11"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gnrcjo2i0rqF"},"source":["A helper function adding silence at the beginning and at the end of each numeral file."]},{"cell_type":"code","metadata":{"id":"qPmBJdzCjD-Y","executionInfo":{"status":"ok","timestamp":1618311359412,"user_tz":-60,"elapsed":644,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["from pydub import AudioSegment\n","\n","def addSilence(silence):\n","  # read all chunk files\n","  numeral_files = glob.glob('./chunk*.wav')\n","  # create 1 sec of silence audio segment\n","  one_sec_segment = AudioSegment.silent(duration=silence)  #duration in milliseconds\n","  # iterate over files\n","  for file in numeral_files:\n","    # read wav file to an audio segment\n","    sound = AudioSegment.from_wav(file)\n","    # add silence at the beginning and at the end\n","    final_sound = one_sec_segment + sound + one_sec_segment\n","    # save the amended file\n","    final_sound.export(file, format=\"wav\")"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4C6ZHSTFQSZh"},"source":["### Putting it all together - the model"]},{"cell_type":"markdown","metadata":{"id":"yiOLA7zsHnpm"},"source":["The code below uses some of the functions developed earlier. It requires the relevant files to be uploaded to Collab panel on the left. The files can be found on by GitHub at:<br>\n","https://github.com/maciejtarsa/MLEnd-Spoken-Numerals/tree/main/telephone_numbers <br><br>\n","Initially, I was aiming to test this on 5 telephone numbers spoken by two speakers. After initial dissapointing results, I decided to include 5 telephone numbers put together from the training data (it should therefore contain 11 speakers pronuncing a numeral each). Hence, I ended up with 15 files, 5 by speaker 1, 5 by speaker 2 and 5 put together by randomly selected speakers."]},{"cell_type":"code","metadata":{"id":"XQxrUowrxiBj","executionInfo":{"status":"ok","timestamp":1618311459978,"user_tz":-60,"elapsed":439,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}}},"source":["# Set up a dataframe to compare results\n","# only need to do this once\n","\n","telephone_results = pd.DataFrame(\n","      [['M_1.wav', '07486124390','',''],\n","      ['M_2.wav', '84566510972','',''],\n","      ['M_3.wav', '61237890121','',''],\n","      ['M_4.wav', '94459718231','',''],\n","      ['M_5.wav', '07578414321','',''],\n","      ['V_1.wav', '07486124390','',''],\n","      ['V_2.wav', '84566510972','',''],\n","      ['V_3.wav', '61237890121','',''],\n","      ['V_4.wav', '94459718231','',''],\n","      ['V_5.wav', '07578414321','',''],\n","      ['R_1.wav', '22459577439','',''],\n","      ['R_2.wav', '32996314224','',''],\n","      ['R_3.wav', '75093654553','',''],\n","      ['R_4.wav', '47295281336','',''],\n","      ['R_5.wav', '21404158635','','']],\n","      columns = ['File', 'Actual', 'Predicted', 'Accuracy']) "],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":769},"id":"ibmXxPj4QNsk","executionInfo":{"status":"ok","timestamp":1618311506300,"user_tz":-60,"elapsed":43826,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"789af070-f1bf-4936-c849-246504552ae2"},"source":["# create a list of .wav files to import\n","telephone_files = glob.glob('./*_*.wav')\n","# iterate over them\n","for telephone in telephone_files:\n","  tel_file = telephone\n","  # chunk the file\n","  chunks = split(tel_file)\n","  # save chunks as .wav files in the local collab environment\n","  for i, chunk in enumerate(chunks):\n","    chunk.export(\"./chunk{0}.wav\".format(i), format=\"wav\")\n","  # add silence to all chink files\n","  # addSilence(500)\n","  # create a list of .wav files to import\n","  numeral_files = glob.glob('./chunk*.wav')\n","  # extract features\n","  X = getX(numeral_files)\n","  # run the model\n","  runModel()\n","# print all results\n","telephone_results"],"execution_count":35,"outputs":[{"output_type":"stream","text":["100%|██████████| 11/11 [00:02<00:00,  4.25it/s]\n","100%|██████████| 11/11 [00:01<00:00,  5.55it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.63it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.50it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.64it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.68it/s]\n","100%|██████████| 11/11 [00:02<00:00,  5.25it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.23it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.31it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.63it/s]\n","100%|██████████| 11/11 [00:02<00:00,  5.40it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.31it/s]\n","100%|██████████| 11/11 [00:02<00:00,  5.10it/s]\n","100%|██████████| 11/11 [00:02<00:00,  4.19it/s]\n","100%|██████████| 11/11 [00:01<00:00,  5.60it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Actual</th>\n","      <th>Predicted</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M_1.wav</td>\n","      <td>07486124390</td>\n","      <td>86739763397</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M_2.wav</td>\n","      <td>84566510972</td>\n","      <td>36277971693</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M_3.wav</td>\n","      <td>61237890121</td>\n","      <td>87333131760</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M_4.wav</td>\n","      <td>94459718231</td>\n","      <td>89777379736</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M_5.wav</td>\n","      <td>07578414321</td>\n","      <td>98673661607</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>V_1.wav</td>\n","      <td>07486124390</td>\n","      <td>16799173837</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>V_2.wav</td>\n","      <td>84566510972</td>\n","      <td>46779971693</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>V_3.wav</td>\n","      <td>61237890121</td>\n","      <td>77182191260</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>V_4.wav</td>\n","      <td>94459718231</td>\n","      <td>19762379796</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>V_5.wav</td>\n","      <td>07578414321</td>\n","      <td>96773199607</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>R_1.wav</td>\n","      <td>22459577439</td>\n","      <td>39377106769</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>R_2.wav</td>\n","      <td>32996314224</td>\n","      <td>16136861300</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>R_3.wav</td>\n","      <td>75093654553</td>\n","      <td>74761938161</td>\n","      <td>0.0909091</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>R_4.wav</td>\n","      <td>47295281336</td>\n","      <td>69782493910</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>R_5.wav</td>\n","      <td>21404158635</td>\n","      <td>38086757038</td>\n","      <td>0.181818</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       File       Actual    Predicted   Accuracy\n","0   M_1.wav  07486124390  86739763397   0.181818\n","1   M_2.wav  84566510972  36277971693          0\n","2   M_3.wav  61237890121  87333131760  0.0909091\n","3   M_4.wav  94459718231  89777379736  0.0909091\n","4   M_5.wav  07578414321  98673661607  0.0909091\n","5   V_1.wav  07486124390  16799173837  0.0909091\n","6   V_2.wav  84566510972  46779971693          0\n","7   V_3.wav  61237890121  77182191260  0.0909091\n","8   V_4.wav  94459718231  19762379796          0\n","9   V_5.wav  07578414321  96773199607  0.0909091\n","10  R_1.wav  22459577439  39377106769  0.0909091\n","11  R_2.wav  32996314224  16136861300  0.0909091\n","12  R_3.wav  75093654553  74761938161  0.0909091\n","13  R_4.wav  47295281336  69782493910          0\n","14  R_5.wav  21404158635  38086757038   0.181818"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"YTawIiTTKl8C"},"source":["The results are very dissapointing, the model is capable of predicting at most 2 characters, performance is essentially as bad as or even worse than random.<br><br>\n","I noticed that the way pydub was splitting the sound files was that individual chunks did not have any leading or following silence. I tried adding it, hoping the performance would improve. I experimented with a few different durations of the silnce. Unfortunately, it made no difference to the performance of the model. It did make the processing of each telephone number take longer. Silence of 1000 miliseconds took about 6s to process each file, silcence of 500 miliseconds 4s to process each file. Without adding the silnce, it took about 2s per file. Hence I did not include the additional silence in the end."]},{"cell_type":"markdown","metadata":{"id":"8k5W8oIgKu9L"},"source":["Let's create a random set of numbers and compare that to the performance of my model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"id":"iXv6UGBmLE5e","executionInfo":{"status":"ok","timestamp":1618311521398,"user_tz":-60,"elapsed":690,"user":{"displayName":"Maciej Tarsa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWk0j9fFSgnb3uzugIZcEXR3uc9Ze0OcOZznFdZA4=s64","userId":"17023749594418169578"}},"outputId":"174e6a78-c3ea-4b71-8ae9-b399df49531a"},"source":["from random import randint\n","# add new column to the data frame\n","telephone_results['Random_number'] = ''\n","telephone_results['Random_accuracy'] = ''\n","\n","for i, row in telephone_results.iterrows():\n","  string = ''\n","  for _ in range(11):\n","    string += str(randint(0,9))\n","  telephone_results.loc[i,'Random_number'] = string\n","  # calculate the accuracy by comparing the strings\n","  actual_string = str(telephone_results.loc[i, 'Actual'])\n","  sum = 0\n","  if len(actual_string) == 11:\n","    for j in range(11):\n","      if string[j] == actual_string[j]:\n","        sum += 1\n","  telephone_results.loc[i,'Random_accuracy'] =  sum/11\n","\n","# convert the accuracy columns to numeric\n","telephone_results['Accuracy'] = pd.to_numeric(telephone_results['Accuracy'])\n","telephone_results['Random_accuracy'] = pd.to_numeric(telephone_results['Random_accuracy'])\n","# and random numbers as string\n","telephone_results['Random_number'] = telephone_results['Random_number'].astype(str)\n","# add an average row\n","telephone_results.loc['mean'] = telephone_results.mean()\n","# print the results\n","telephone_results"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File</th>\n","      <th>Actual</th>\n","      <th>Predicted</th>\n","      <th>Accuracy</th>\n","      <th>Random_number</th>\n","      <th>Random_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M_1.wav</td>\n","      <td>07486124390</td>\n","      <td>86739763397</td>\n","      <td>0.181818</td>\n","      <td>93431037153</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M_2.wav</td>\n","      <td>84566510972</td>\n","      <td>36277971693</td>\n","      <td>0.000000</td>\n","      <td>53160768749</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M_3.wav</td>\n","      <td>61237890121</td>\n","      <td>87333131760</td>\n","      <td>0.090909</td>\n","      <td>53752461528</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M_4.wav</td>\n","      <td>94459718231</td>\n","      <td>89777379736</td>\n","      <td>0.090909</td>\n","      <td>64509819925</td>\n","      <td>0.272727</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M_5.wav</td>\n","      <td>07578414321</td>\n","      <td>98673661607</td>\n","      <td>0.090909</td>\n","      <td>07319137258</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>V_1.wav</td>\n","      <td>07486124390</td>\n","      <td>16799173837</td>\n","      <td>0.090909</td>\n","      <td>76287357380</td>\n","      <td>0.272727</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>V_2.wav</td>\n","      <td>84566510972</td>\n","      <td>46779971693</td>\n","      <td>0.000000</td>\n","      <td>66218607982</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>V_3.wav</td>\n","      <td>61237890121</td>\n","      <td>77182191260</td>\n","      <td>0.090909</td>\n","      <td>06981556177</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>V_4.wav</td>\n","      <td>94459718231</td>\n","      <td>19762379796</td>\n","      <td>0.000000</td>\n","      <td>74176990509</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>V_5.wav</td>\n","      <td>07578414321</td>\n","      <td>96773199607</td>\n","      <td>0.090909</td>\n","      <td>36826355958</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>R_1.wav</td>\n","      <td>22459577439</td>\n","      <td>39377106769</td>\n","      <td>0.090909</td>\n","      <td>73416019284</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>R_2.wav</td>\n","      <td>32996314224</td>\n","      <td>16136861300</td>\n","      <td>0.090909</td>\n","      <td>73725586043</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>R_3.wav</td>\n","      <td>75093654553</td>\n","      <td>74761938161</td>\n","      <td>0.090909</td>\n","      <td>74011878746</td>\n","      <td>0.181818</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>R_4.wav</td>\n","      <td>47295281336</td>\n","      <td>69782493910</td>\n","      <td>0.000000</td>\n","      <td>27062808760</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>R_5.wav</td>\n","      <td>21404158635</td>\n","      <td>38086757038</td>\n","      <td>0.181818</td>\n","      <td>69791957221</td>\n","      <td>0.090909</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>NaN</td>\n","      <td>4.99075e+162</td>\n","      <td>5.78265e+163</td>\n","      <td>0.078788</td>\n","      <td>6.22874e+163</td>\n","      <td>0.121212</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         File        Actual  ... Random_number  Random_accuracy\n","0     M_1.wav   07486124390  ...   93431037153         0.090909\n","1     M_2.wav   84566510972  ...   53160768749         0.090909\n","2     M_3.wav   61237890121  ...   53752461528         0.090909\n","3     M_4.wav   94459718231  ...   64509819925         0.272727\n","4     M_5.wav   07578414321  ...   07319137258         0.181818\n","5     V_1.wav   07486124390  ...   76287357380         0.272727\n","6     V_2.wav   84566510972  ...   66218607982         0.181818\n","7     V_3.wav   61237890121  ...   06981556177         0.090909\n","8     V_4.wav   94459718231  ...   74176990509         0.090909\n","9     V_5.wav   07578414321  ...   36826355958         0.000000\n","10    R_1.wav   22459577439  ...   73416019284         0.090909\n","11    R_2.wav   32996314224  ...   73725586043         0.000000\n","12    R_3.wav   75093654553  ...   74011878746         0.181818\n","13    R_4.wav   47295281336  ...   27062808760         0.090909\n","14    R_5.wav   21404158635  ...   69791957221         0.090909\n","mean      NaN  4.99075e+162  ...  6.22874e+163         0.121212\n","\n","[16 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"pnA66BIudzD0"},"source":["Randomly generated numbers are performing better than the model trained. The randomly generated number achieved the accuracy of around 0.12, my model achieved the accuracy of 0.08. I was hoping for at least similar accuracy to the validation accuracy, which was around 0.3. I would have expected at least the files put together from the training data to perform better, but unfortunately, none of the files performed satisfactory."]},{"cell_type":"markdown","metadata":{"id":"J-eUfdDBAbRx"},"source":["### Conclusions"]},{"cell_type":"markdown","metadata":{"id":"cAuQLP3CWVIl"},"source":["Unfortunately, the model I developed was not capable of performing well in a deployment scenario. The model was not great to begin with, as it only achieved validation accuracy of 30%, which is better that random (1 in 10 or 10%), but still not very accurate. When deployed to recognise digits from a spoken telephone number (11 digits), it only achieved accuracy of 6%. Number generated by random number generator achieved accuracy of 8% on the same data. <br><br>\n","\n","For testing of this product, I used a series of numbers spoken by myself (Polish native speaker), my wife (English native speaker) and numerals randomly selected from the testing/validation dataset. Each subset achieved the following results:\n"," - out of a set of 5, 11-long numbers spoken by muself (files beginning with M), the model correctly recognised 5 digits \n"," - out of a set of 5, 11-long numbers spoken by my wife (files beginning with V), the model correctly recognised 3 digits\n"," - out of a set of 5, 11-long numbers spoken by random participants from training/validation data (files starting with R), 5 were recognised correctly<br><br>\n","\n","The number spoken by an English native speaker achieved the worst performance, perhaps indicating that accent of the speaker plays a heavy role in digit recognition. However, I would have expected for the ones taken from training/validation to perform slightly better. Potentially, providing the model with mode test data would provide more insight on this.<br><br>\n","Perhaps exploring a more complicated model, such as neural network, would produce better results in this case.<br><br>\n","Furthermore, it might be possible to improve the model by expanding the training dataset, e.g. additionally using spoken digits dataset:<br>\n","https://www.tensorflow.org/datasets/catalog/spoken_digit<br><br>\n","\n","\n"]}]}